{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OOeAf6ca__G1"
      },
      "outputs": [],
      "source": [
        "# Core TensorFlow and Keras imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "# CIFAR-10 contains 60,000 32x32 RGB images across 10 classes\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Convert class labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Preprocessing function:\n",
        "# - Resize images to 224x224 to match EfficientNet input requirements\n",
        "# - Normalize pixel values to [0, 1]\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (224,224))\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Create TensorFlow Dataset for efficient input pipeline\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds = train_ds.map(preprocess).shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_ds = test_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "okauyGq2A43U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d8c827-970e-4141-c5f3-d6f90f13ff57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline CNN model trained from scratch (no pre-trained knowledge)\n",
        "# Acts as a performance reference point\n",
        "baseline_model = models.Sequential([\n",
        "    layers.Conv2D(32, 3, activation='relu', input_shape=(224,224,3)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "baseline_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "baseline_history = baseline_model.fit(\n",
        "    train_ds,  # Use the preprocessed dataset\n",
        "    epochs=5,\n",
        "    validation_data=test_ds # Use the preprocessed test dataset for validation\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1lJs6gtBqNO",
        "outputId": "1c57db1e-a7aa-4883-f529-2958af725905"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 54ms/step - accuracy: 0.3875 - loss: 1.8108 - val_accuracy: 0.5117 - val_loss: 1.3591\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.5357 - loss: 1.3074 - val_accuracy: 0.5366 - val_loss: 1.3064\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 51ms/step - accuracy: 0.6047 - loss: 1.1115 - val_accuracy: 0.5747 - val_loss: 1.2033\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 51ms/step - accuracy: 0.6668 - loss: 0.9410 - val_accuracy: 0.5665 - val_loss: 1.3092\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.7292 - loss: 0.7645 - val_accuracy: 0.5675 - val_loss: 1.4698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNetB0 pre-trained on ImageNet\n",
        "# include_top=False removes the original ImageNet classifier\n",
        "base_model = EfficientNetB0(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224,224,3)\n",
        ")\n",
        "\n",
        "# Freeze all layers of the pre-trained model\n",
        "# This prevents updating ImageNet-learned weights\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "0lkW-du-GTDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train only the newly added classifier layers\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=5,\n",
        "    validation_data=test_ds\n",
        ")\n"
      ],
      "metadata": {
        "id": "p014gINHGWvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the pre-trained EfficientNet layers\n",
        "# Allows full network to adapt to CIFAR-10 domain\n",
        "base_model.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Recompile with a very small learning rate\n",
        "# This avoids destroying pre-trained features (catastrophic forgetting)\n",
        "fine_tune_history =model.fit(\n",
        "    train_ds,\n",
        "    epochs=3,\n",
        "    validation_data=test_ds\n",
        ")\n"
      ],
      "metadata": {
        "id": "k_U-19Y5Imz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(baseline_history.history['accuracy'], label='Baseline Train')\n",
        "plt.plot(baseline_history.history['val_accuracy'], label='Baseline Val')\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='TL Train (Frozen)')\n",
        "plt.plot(history.history['val_accuracy'], label='TL Val (Frozen)')\n",
        "\n",
        "plt.plot(\n",
        "    range(len(history.history['accuracy']),\n",
        "          len(history.history['accuracy']) + len(fine_tune_history.history['accuracy'])),\n",
        "    fine_tune_history.history['accuracy'],\n",
        "    label='TL Train (Fine-tuned)'\n",
        ")\n",
        "\n",
        "plt.title(\"Accuracy Comparison: Baseline vs Transfer Learning\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-6aWY0m0MsuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_test_acc = baseline_model.evaluate(test_ds, verbose=0)[1]\n",
        "tl_test_acc = model.evaluate(test_ds, verbose=0)[1]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(['Baseline CNN', 'Transfer Learning'],\n",
        "        [baseline_test_acc, tl_test_acc])\n",
        "plt.title(\"Test Accuracy Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H944GrOoMa95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(model, dataset, title):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        preds = model.predict(images, verbose=0)\n",
        "        y_pred.extend(np.argmax(preds, axis=1))\n",
        "        y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(baseline_model, test_ds, \"Baseline CNN Confusion Matrix\")\n",
        "plot_confusion_matrix(model, test_ds, \"Transfer Learning Confusion Matrix\")\n"
      ],
      "metadata": {
        "id": "-ytHMzbPpxSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Key Observation\n",
        "- Feature extraction alone resulted in low accuracy due to domain mismatch\n",
        "- Fine-tuning enabled EfficientNet to adapt its representations to CIFAR-10\n",
        "- Demonstrates the importance of controlled fine-tuning in transfer learning\n"
      ],
      "metadata": {
        "id": "ECILDek-wuM-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}